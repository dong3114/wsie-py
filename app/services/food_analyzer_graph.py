# -*- coding: utf-8 -*-
"""ìŒì‹ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bgOxKRuNAprhnL0U9Dnv1U3BfoXnfKUd
"""

# -*- coding: utf-8 -*-
"""
ìŒì‹ë¬¼ ì“°ë ˆê¸° ì´ë¯¸ì§€ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
"""
from dotenv import load_dotenv
load_dotenv()

import base64
import os
import json
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langgraph.graph import StateGraph, END
from typing import TypedDict

# -----------------------------
# 0. ì´ˆê¸°í™”
# -----------------------------
# API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜(OPENAI_API_KEY)ì— ì„¤ì •í•´ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
try:
    client = OpenAI()
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
except Exception as e:
    print(f"ğŸš¨ OpenAI ë˜ëŠ” LangChain ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    print("OPENAI_API_KEYê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    print(f"ì˜¤ë¥˜ ìƒì„¸: {e}")
    exit()


# -----------------------------
# ìƒíƒœ ì •ì˜
# -----------------------------
class State(TypedDict):
    analysis: str
    report: str
    improvements: str


# -----------------------------
# 1. ë©€í‹°ëª¨ë‹¬ ë¶„ì„ í•¨ìˆ˜
# -----------------------------
def analyze_food(image_path: str) -> str:
    """ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ GPT-4oë¡œ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        with open(image_path, "rb") as f:
            img_bytes = f.read()
        img_base64 = base64.b64encode(img_bytes).decode("utf-8")

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë‚¨ê¸´ ìŒì‹ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.",
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ìŒì‹ ì‚¬ì§„ì„ ë³´ê³  ìŒì‹ ì¢…ë¥˜ì™€ ë‚¨ì€ ì–‘ì„ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.",
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{img_base64}"
                            },
                        },
                    ],
                },
            ],
        )
        return response.choices[0].message.content
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {image_path}")
        return None
    except Exception as e:
        print(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# -----------------------------
# 2. ë‹¨ì¼ ë…¸ë“œ: report + improve í†µí•©
# -----------------------------
combined_prompt = PromptTemplate(
    input_variables=["analysis"],
    template="""
ë¶„ì„ ê²°ê³¼: {analysis}

1) ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì”ë°˜ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
2) ë°˜ë“œì‹œ ê°œì„  ë°©ì•ˆì„ 1~3ê°œ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
3) ì ˆëŒ€ improvementsë¥¼ ë¹„ì›Œë‘ì§€ ë§ˆì„¸ìš”.
4) ì¶œë ¥ì€ **ìˆœìˆ˜ JSONë§Œ** ë°˜í™˜í•˜ì„¸ìš”. Markdown, ë¦¬ìŠ¤íŠ¸, ê¸€ë¨¸ë¦¬í‘œ ë“±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

ì¶œë ¥ ì˜ˆì‹œ(JSON í˜•ì‹):
{{
  "report": "ì˜¤ëŠ˜ ì œê³µëœ ìŒì‹ì˜ ì”ë°˜ì´ ...",
  "improvements": [
    {{"suggestion": "ìƒëŸ¬ë“œ ì–‘ ì¡°ì ˆ"}},
    {{"suggestion": "ë“œë ˆì‹± ì¢…ë¥˜ ë‹¤ì–‘í™”"}}
  ]
}}
""",
)
# LangChain Expression Language (LCEL)ì„ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ êµ¬ì„±
combined_chain = combined_prompt | llm


def combined_node(state: State):
    result = combined_chain.invoke({"analysis": state["analysis"]})
    try:
        # ë¬¸ìì—´ JSON â†’ dictë¡œ ë³€í™˜
        output = json.loads(result.content)
    except json.JSONDecodeError:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìµœì†Œí•œ reportë§Œ ë°˜í™˜
        output = {"report": result.content, "improvements": "LLM ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨"}
    return output


# -----------------------------
# 3. LangGraph êµ¬ì„±
# -----------------------------
def build_graph():
    """LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•˜ê³  ì»´íŒŒì¼í•©ë‹ˆë‹¤."""
    graph = StateGraph(State)

    graph.add_node("analyze", lambda s: {"analysis": s["analysis"]})
    graph.add_node("combined", combined_node)

    graph.set_entry_point("analyze")
    graph.add_edge("analyze", "combined")
    graph.add_edge("combined", END)

    return graph.compile()


# -----------------------------
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------
def main():
    """ë©”ì¸ ì‹¤í–‰ ë¡œì§"""
    print("--- ìŒì‹ë¬¼ ì“°ë ˆê¸° ë¶„ì„ê¸° ---")

    # ì‹¤í–‰ ì˜ˆì‹œ
    image_path = input(
        "ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ./data/Waffles50.jpg): "
    )

    if not os.path.exists(image_path):
        print(f"ì˜¤ë¥˜: '{image_path}' ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\n1. ì´ë¯¸ì§€ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
    analysis_result = analyze_food(image_path)

    if analysis_result:
        print("ë¶„ì„ ì™„ë£Œ!")

        app = build_graph()

        print("\n2. ë¦¬í¬íŠ¸ ë° ê°œì„  ë°©ì•ˆì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
        final_output = app.invoke({"analysis": analysis_result})
        print("ìƒì„± ì™„ë£Œ!")

        print("\n--- ìµœì¢… ê²°ê³¼ ---")
        print("ğŸ“Œ ë¦¬í¬íŠ¸:")
        print(final_output.get("report", "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"))

        print("\nğŸ“Œ ê°œì„  ë°©ì•ˆ:")
        improvements = final_output.get("improvements", [])
        if isinstance(improvements, list):
            for item in improvements:
                print(f"- {item.get('suggestion', 'ê°œì„  ë°©ì•ˆ ì—†ìŒ')}")
        else:
            print(improvements)


if __name__ == "__main__":
    main()
